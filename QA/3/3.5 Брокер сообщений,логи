
Брокер сообщений — это посредник, который управляет обменом сообщений между различными приложениями или системами. Его задача — обеспечить надёжную
и эффективную передачу данных, особенно в асинхронных системах, где отправитель и получатель не обязательно работают одновременно.

Здесь возможны несколько вариантов:
- Сообщение отправляется напрямую от отправителя к получателю.(каждое сообщение используется только однократно;)
- Схема публикации/подписки.(отправитель не знает своих получателей и просто публикует сообщения в определённую тему.)

Основные функции брокера сообщений:
1. Прием и хранение сообщений 
2. Маршрутизация сообщений
3. Управление очередями 
4. Гарантия доставки
5. Поддержка различных протоколов и форматов.

Примеры применения
- В микросервисной архитектуре для связи между сервисами.
- Для обработки данных в режиме реального времени, например, в стриминговых платформах.
- В IoT-системах, где устройства отправляют данные через брокера в центральное хранилище или сервер обработки.
Примеры брокеров:
- Apache Kafka — мощный брокер для обработки больших потоков данных.
- RabbitMQ — брокер с гибкой маршрутизацией сообщений и очередями.
- ActiveMQ — популярный брокер с поддержкой различных протоколов.
- Redis и Amazon SQS — могут использоваться для простых очередей сообщений.

KAFKA
Основы кластера Kafka — это продюсер, брокер и консумер. Продюсер пишет сообщения в лог брокера, а консумер его читает.
Лог — это упорядоченный поток событий во времени. Событие происходит, попадает в конец лога и остаётся там неизменным.
Продюсер
Продюсер (или производитель, producer) — это компонент, который отвечает за создание и отправку сообщений в Kafka-кластер. Продюсер записывает 
сообщение в Kafka, тот сохраняет события, возвращает подтверждение о записи или acknowledgement. Продюсер получает его и начинает следующую запись.
Брокеры
Kafka состоит из серверов, которые называют брокерами. Они получают сообщения от продюсеров, хранят их и передают получателям.
Консумеры
Получатели данных, называемые "консюмерами", подписываются на темы и читают нужные им сообщения. Например, аналитическая программа может получать 
данные из темы "активность пользователей", чтобы отслеживать статистику.
Архитектура Kafka
Кластер Kafka позволяет изолировать консумеры и продюсеры друг от друга. Продюсер ничего не знает о консумерах при записи данных в брокер, а консумер 
ничего не знает о продюсере данных.
Zookeeper — это выделенный кластер серверов для образования кворума-согласия и поддержки внутренних процессов Kafka. Благодаря этому инструменту мы 
можем управлять кластером Kafka: добавлять пользователей и топики, задавать им настройки.
Основные задачи Zookeeper:
- Управление конфигурацией(хранит и обновляет конффигурацию распределенных прилодений)
- Обнаружение сервисов (позводляет различным частям сервисов находить друг друга)
- Управление лидерством(следит и определяет главный сервер)
- Синхронизация данных и координация(обечпечивает синхронизацию между разными копмонентами, предотвращая конфликты)
Топик — это логическое разделение категорий сообщений на группы. (события по статусам заказов, координат партнёров, маршрутных листов и так далее.)
Ограничений на количество топиков в кластере Kafka нет, но есть ограничения самого компьютера.
Топики в Kafka разделены на партиции.
Партиции позволяют обрабатывать сообщения параллельно, что увеличивает скорость и масштабируемость Kafka. Сообщения внутри партиции упорядочены по 
времени.
ТОпик -->Партиции-->Сегменты
Сегменты - Это отдельные файлы, которые можно создать, ротировать или удалить в соответствии с настройкой устаревания данных в них. 
log-start offset - Начальная позиция первого сообщения в логе
log-end offset - Позиция сообщения, записанного последним
current offset - Позиция консумера сейчас
Лаг- это Расстояние между конечным оффсетом и текущим оффсетом консумера
Репликация Данных
У каждой партиции есть настраиваемое число реплик.
Одна из реплик называется лидером, остальеные фолловерами.Продюсер подключается к брокеру, на котором расположена лидер-партиция, чтобы записать в неё 
данные. Записанные в лидера данные автоматически реплицируются фолловерами внутри кластера Kafka. Они подключаются к лидеру, читают данные и асинхронно
сохраняют к себе на диск. В настроенном кластере Kafka репликация обычно занимает доли секунд.
Консумеры со своей стороны также читают из лидерской партиции — это позволяет достичь консистентности при работе с данными. Задача фолловеров здесь как
и в предыдущем случае сводится к копированию данных от лидера.
Роли лидеров и фолловеров не статичны. Kafka автоматически выбирает роли для партиций в кластере.

Apache Kafka — это распределённая платформа для обработки потоков данных, которая работает по принципу публикации и подписки. Она часто используется 
для сбора, хранения и обработки большого объема данных в реальном времени. 
Основные компоненты Apache Kafka:
1.Продюсер (Producer):
Продюсер — это приложение или служба, которая отправляет сообщения в Kafka.
- Он публикует сообщения в определённый топик (topic), который является логической категорией данных.
- Продюсеры могут работать параллельно и отправлять данные в различные топики.
- Каждый продюсер должен сериализовать свои данные перед отправкой (например, в строки, JSON, Avro и т. д.).
2. Топики (Topics):
Топик — это логическая категория или канал для хранения сообщений в Kafka.
- Все сообщения по определённой теме (например, лог-файлы сервера) отправляются в соответствующий топик.
- Топики разделены на партиции для параллельной обработки и распределённого хранения данных.
3. Партиции (Partitions):
- Каждому топику назначено несколько партиций. Партиции позволяют Kafka распределять данные по нескольким брокерам для высокой производительности и 
масштабируемости.
- Сообщения внутри одной партиции имеют строгий порядок (first-in-first-out), что гарантирует их упорядоченность.
- Каждое сообщение в партиции имеет уникальный offset — позицию сообщения в пределах партиции.
- Партиции делают Kafka горизонтально масштабируемой, поскольку каждая партиция может обрабатываться разными серверами.
4. Потребитель (Consumer):
Потребитель — это приложение или служба, которая считывает данные из топика.
- Потребители объединяются в группы потребителей (consumer groups). Каждое сообщение в топике читается одной потребительской группой, но при этом каждый 
участник группы обрабатывает отдельные партиции, распределённые между ними.
- Это позволяет читать и обрабатывать сообщения параллельно, обеспечивая масштабируемость и балансировку нагрузки.
5. ZooKeeper:
- До версии Kafka 2.8 ZooKeeper использовался для координации и управления метаданными кластера Kafka.
- ZooKeeper хранил информацию о состоянии брокеров и помогал управлять топиками, партициями и репликами.
- В более поздних версиях Kafka встроила свой собственный механизм координации метаданных, и необходимость в ZooKeeper была устранена.
6. Брокеры (Brokers):
Брокер — это сервер Kafka, который обрабатывает данные и запросы.
- Kafka-кластер состоит из нескольких брокеров, которые хранят данные топиков и управляют партициями.
- Один брокер может управлять несколькими топиками и партициями, и кластер Kafka масштабируется путём добавления дополнительных брокеров

Путь сообщения в Kafka
Давайте разберем, как сообщение проходит через систему Kafka от продюсера до потребителя.
Продюсер отправляет сообщение:
- Продюсер сериализует данные и отправляет их в конкретный топик.
- Продюсер определяет, в какую партицию топика будет отправлено сообщение. Это может быть случайный выбор, хеширование ключа сообщения, или 
пользовательская логика.
Сообщение записывается в партицию топика:
- Сообщение записывается в партицию в виде последовательности байтов, что позволяет Kafka быстро и эффективно записывать данные на диск.
- Kafka записывает сообщение в конец партиции с присвоением уникального offset — идентификатора, указывающего позицию сообщения в партиции.
Хранение и репликация сообщений:
- Для обеспечения отказоустойчивости Kafka поддерживает репликацию данных. Каждая партиция может иметь одну или несколько реплик, распределённых по брокерам.
- Если один из брокеров выйдет из строя, Kafka автоматически переключается на реплику, чтобы данные были доступны.
Потребитель читает сообщение:
- Потребитель подключается к Kafka и указывает, из какого топика и каких партиций ему нужно читать сообщения.
- Потребитель использует offset для отслеживания текущей позиции, до которой он дочитал.
- Kafka обеспечивает гарантированное одноразовое чтение сообщений внутри потребительской группы, что означает, что каждый участник группы получает только 
те сообщения, которые предназначены для него (на уровне партиций).
Коммиты offset-ов:
- Потребители могут вручную или автоматически подтверждать (commit) offset после успешной обработки сообщения. Это гарантирует, что при повторном запуске 
потребитель не начнёт чтение с начала, а продолжит с последнего обработанного сообщения.

------------------------------------------------------------------------------
Логи
Логи — это записи событий и сообщений, создаваемые программой или системой во время ее работы. Они представляют собой источник информации о том, что 
происходит внутри приложения в определённый момент времени. Логи содержат различные данные, такие как сообщения об ошибках, предупреждения, информацию о 
выполнении определённых действий и многое другое.
Когда тестировщик смотрит в логи:
- При тестировании новой фичи(Стоит держать логи открытыми, они помогут отследить правильность выполнения определенных операций, последовательность событий
и другие аспекты функциональности приложения.)
- При релизе приложения и проведении регрессионного тестирования (нужно проверять логи, часто в командах это делают разработчики.)
- При проверке взаимодействия с внешними системами (акими как базы данных, API или другие службы. Логи могут содержать информацию о запросах и ответах, 
передаваемых данным, кодах состояния и других деталях взаимодействия.)
- Для более точного определения причины бага и отладки ошибки(В логах может содержаться необходимая информация для идентификации бага, логи могут содержать
полезную информацию о возникших исключениях, трассировке стека, сообщениях об ошибках или недостаточных данных, которые могут помочь воспроизвести и понять
причину ошибки. А чем больше информации мы принесём разработчику, тем быстрее он починит баг.)
- Для оценки производительности приложения.(Логи могут содержать информацию о времени выполнения определенных операций, использовании ресурсов  
и других показателях производительности. Тестировщик может использовать эти данные для определения узких мест в приложении и предложения улучшений.
- При работе с событиями системы. Вас могут попросить разработчики или вам самим потребуется более детальная информация для понимания работы системы. 

Уровни логирования
Уровни логирования определяют, насколько важная информация будет записываться в лог-файлы или выводиться при выполнении программы. На верхнем уровне
находятся самые важные сообщения. 
- FATAL: является наивысшим уровнем критичности логов и указывает на самые критические ошибки и проблемы, которые могут привести к немедленному завершению 
программы или системы. Логи с уровнем FATAL обычно означают серьезные сбои, которые требуют немедленного вмешательства и исправления. 
- ERROR: этот уровень используется для записи ошибок и проблем, которые могут привести к некорректной работе приложения. Логи с уровнем ERROR указывают на 
проблемы, которые требуют вмешательства и исправления.
- WARN: уровень WARN указывает на предупреждения и потенциальные проблемы, которые не являются критическими ошибками. Логи с уровнем WARN могут включать 
сообщения о неправильном использовании приложения, некорректных данных или других ситуациях, требующих внимания.
- INFO: этот уровень предоставляет информацию о ходе работы приложения и важных событиях. Логи с уровнем INFO содержат сообщения, которые помогают 
отслеживать основные операции и состояние приложения
- DEBUG: содержат подробности о ходе выполнения приложения, значимые переменные и другие данные, которые могут быть полезными при обнаружении и исправлении ошибок.
- TRACE: это наиболее подробный уровень логирования. Логи с уровнем TRACE содержат очень подробную информацию о состоянии приложения, включая значения 
переменных, шаги выполнения и другие детали. Они обычно используются во время отладки и разработки для более глубокого анализа приложения.

Тестировщик чаще всего работает с ошибками (ERROR, реже FATAL) и c предупреждениями (WARN). Но для получения информации иногда, бывает, обращается к 
информационным логам (INFO). 
ВИДЫ ЛОГОВ:
1. Логи приложений (Application logs). Это логи, создаваемые самим приложением в процессе его работы. Это может быть веб, десктоп и мобильное приложение.
Они содержат информацию о выполнении операций, событиях, ошибочных ситуациях, запросах, ответах и других событиях, внутри приложения.
2. Логи сервера (Server logs). Это логи, генерируемые серверами и веб-серверами. Они содержат информацию о работе сервера, запросах, ошибочных ситуациях,
подключениях и других событиях, происходящих на сервере. Логи сервера помогают администраторам серверов и разработчикам отслеживать состояние сервера, 
обнаруживать проблемы с производительностью, безопасностью и настраивать серверное окружение.
  Логи сервера часто делятся на два типа: 
  - Error logs (это информация об ошибках)
  - Access Logs (общая информация о запросах и ответах к серверу) 
3. Системные логи (System logs): Это логи, записываемые операционной системой. Они содержат информацию о работе операционной системы, событиях, ошибках, 
состоянии системы, процессах, сетевых подключениях и других системных событиях.
---------------для тестировщика првые 3
4. Логи доступа
5. Логи аудита



















