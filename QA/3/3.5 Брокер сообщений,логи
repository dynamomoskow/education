
Брокер сообщений — это посредник, который управляет обменом сообщений между различными приложениями или системами. Его задача — обеспечить надёжную
и эффективную передачу данных, особенно в асинхронных системах, где отправитель и получатель не обязательно работают одновременно.

Здесь возможны несколько вариантов:
- Сообщение отправляется напрямую от отправителя к получателю.(каждое сообщение используется только однократно;)
- Схема публикации/подписки.(отправитель не знает своих получателей и просто публикует сообщения в определённую тему.)

Основные функции брокера сообщений:
1. Прием и хранение сообщений 
2. Маршрутизация сообщений
3. Управление очередями 
4. Гарантия доставки
5. Поддержка различных протоколов и форматов.

Примеры применения
- В микросервисной архитектуре для связи между сервисами.
- Для обработки данных в режиме реального времени, например, в стриминговых платформах.
- В IoT-системах, где устройства отправляют данные через брокера в центральное хранилище или сервер обработки.
Примеры брокеров:
- Apache Kafka — мощный брокер для обработки больших потоков данных.
- RabbitMQ — брокер с гибкой маршрутизацией сообщений и очередями.
- ActiveMQ — популярный брокер с поддержкой различных протоколов.
- Redis и Amazon SQS — могут использоваться для простых очередей сообщений.

KAFKA
Основы кластера Kafka — это продюсер, брокер и консумер. Продюсер пишет сообщения в лог брокера, а консумер его читает.
Лог — это упорядоченный поток событий во времени. Событие происходит, попадает в конец лога и остаётся там неизменным.
Продюсер
Продюсер (или производитель, producer) — это компонент, который отвечает за создание и отправку сообщений в Kafka-кластер. Продюсер записывает 
сообщение в Kafka, тот сохраняет события, возвращает подтверждение о записи или acknowledgement. Продюсер получает его и начинает следующую запись.
Брокеры
Kafka состоит из серверов, которые называют брокерами. Они получают сообщения от продюсеров, хранят их и передают получателям.
Консумеры
Получатели данных, называемые "консюмерами", подписываются на темы и читают нужные им сообщения. Например, аналитическая программа может получать 
данные из темы "активность пользователей", чтобы отслеживать статистику.
Архитектура Kafka
Кластер Kafka позволяет изолировать консумеры и продюсеры друг от друга. Продюсер ничего не знает о консумерах при записи данных в брокер, а консумер 
ничего не знает о продюсере данных.
Zookeeper — это выделенный кластер серверов для образования кворума-согласия и поддержки внутренних процессов Kafka. Благодаря этому инструменту мы 
можем управлять кластером Kafka: добавлять пользователей и топики, задавать им настройки.
Основные задачи Zookeeper:
- Управление конфигурацией(хранит и обновляет конффигурацию распределенных прилодений)
- Обнаружение сервисов (позводляет различным частям сервисов находить друг друга)
- Управление лидерством(следит и определяет главный сервер)
- Синхронизация данных и координация(обечпечивает синхронизацию между разными копмонентами, предотвращая конфликты)
Топик — это логическое разделение категорий сообщений на группы. (события по статусам заказов, координат партнёров, маршрутных листов и так далее.)
Ограничений на количество топиков в кластере Kafka нет, но есть ограничения самого компьютера.
Топики в Kafka разделены на партиции.
Партиции позволяют обрабатывать сообщения параллельно, что увеличивает скорость и масштабируемость Kafka. Сообщения внутри партиции упорядочены по 
времени.
ТОпик -->Партиции-->Сегменты
Сегменты - Это отдельные файлы, которые можно создать, ротировать или удалить в соответствии с настройкой устаревания данных в них. 
log-start offset - Начальная позиция первого сообщения в логе
log-end offset - Позиция сообщения, записанного последним
current offset - Позиция консумера сейчас
Лаг- это Расстояние между конечным оффсетом и текущим оффсетом консумера
Репликация Данных
У каждой партиции есть настраиваемое число реплик.
Одна из реплик называется лидером, остальеные фолловерами.Продюсер подключается к брокеру, на котором расположена лидер-партиция, чтобы записать в неё 
данные. Записанные в лидера данные автоматически реплицируются фолловерами внутри кластера Kafka. Они подключаются к лидеру, читают данные и асинхронно
сохраняют к себе на диск. В настроенном кластере Kafka репликация обычно занимает доли секунд.
Консумеры со своей стороны также читают из лидерской партиции — это позволяет достичь консистентности при работе с данными. Задача фолловеров здесь как
и в предыдущем случае сводится к копированию данных от лидера.
Роли лидеров и фолловеров не статичны. Kafka автоматически выбирает роли для партиций в кластере.

Apache Kafka — это распределённая платформа для обработки потоков данных, которая работает по принципу публикации и подписки. Она часто используется 
для сбора, хранения и обработки большого объема данных в реальном времени. 
Основные компоненты Apache Kafka:
1.Продюсер (Producer):
Продюсер — это приложение или служба, которая отправляет сообщения в Kafka.
- Он публикует сообщения в определённый топик (topic), который является логической категорией данных.
- Продюсеры могут работать параллельно и отправлять данные в различные топики.
- Каждый продюсер должен сериализовать свои данные перед отправкой (например, в строки, JSON, Avro и т. д.).
2. Топики (Topics):
Топик — это логическая категория или канал для хранения сообщений в Kafka.
- Все сообщения по определённой теме (например, лог-файлы сервера) отправляются в соответствующий топик.
- Топики разделены на партиции для параллельной обработки и распределённого хранения данных.
3. Партиции (Partitions):
- Каждому топику назначено несколько партиций. Партиции позволяют Kafka распределять данные по нескольким брокерам для высокой производительности и 
масштабируемости.
- Сообщения внутри одной партиции имеют строгий порядок (first-in-first-out), что гарантирует их упорядоченность.
- Каждое сообщение в партиции имеет уникальный offset — позицию сообщения в пределах партиции.
- Партиции делают Kafka горизонтально масштабируемой, поскольку каждая партиция может обрабатываться разными серверами.
4. Потребитель (Consumer):
Потребитель — это приложение или служба, которая считывает данные из топика.
- Потребители объединяются в группы потребителей (consumer groups). Каждое сообщение в топике читается одной потребительской группой, но при этом каждый 
участник группы обрабатывает отдельные партиции, распределённые между ними.
- Это позволяет читать и обрабатывать сообщения параллельно, обеспечивая масштабируемость и балансировку нагрузки.
5. ZooKeeper:
- До версии Kafka 2.8 ZooKeeper использовался для координации и управления метаданными кластера Kafka.
- ZooKeeper хранил информацию о состоянии брокеров и помогал управлять топиками, партициями и репликами.
- В более поздних версиях Kafka встроила свой собственный механизм координации метаданных, и необходимость в ZooKeeper была устранена.
6. Брокеры (Brokers):
Брокер — это сервер Kafka, который обрабатывает данные и запросы.
- Kafka-кластер состоит из нескольких брокеров, которые хранят данные топиков и управляют партициями.
- Один брокер может управлять несколькими топиками и партициями, и кластер Kafka масштабируется путём добавления дополнительных брокеров

Путь сообщения в Kafka
Давайте разберем, как сообщение проходит через систему Kafka от продюсера до потребителя.
Продюсер отправляет сообщение:
- Продюсер сериализует данные и отправляет их в конкретный топик.
- Продюсер определяет, в какую партицию топика будет отправлено сообщение. Это может быть случайный выбор, хеширование ключа сообщения, или 
пользовательская логика.
Сообщение записывается в партицию топика:
- Сообщение записывается в партицию в виде последовательности байтов, что позволяет Kafka быстро и эффективно записывать данные на диск.
- Kafka записывает сообщение в конец партиции с присвоением уникального offset — идентификатора, указывающего позицию сообщения в партиции.
Хранение и репликация сообщений:
- Для обеспечения отказоустойчивости Kafka поддерживает репликацию данных. Каждая партиция может иметь одну или несколько реплик, распределённых по брокерам.
- Если один из брокеров выйдет из строя, Kafka автоматически переключается на реплику, чтобы данные были доступны.
Потребитель читает сообщение:
- Потребитель подключается к Kafka и указывает, из какого топика и каких партиций ему нужно читать сообщения.
- Потребитель использует offset для отслеживания текущей позиции, до которой он дочитал.
- Kafka обеспечивает гарантированное одноразовое чтение сообщений внутри потребительской группы, что означает, что каждый участник группы получает только 
те сообщения, которые предназначены для него (на уровне партиций).
Коммиты offset-ов:
- Потребители могут вручную или автоматически подтверждать (commit) offset после успешной обработки сообщения. Это гарантирует, что при повторном запуске 
потребитель не начнёт чтение с начала, а продолжит с последнего обработанного сообщения.
